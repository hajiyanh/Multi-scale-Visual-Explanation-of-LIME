# Multi-scale_Visual_Explanation-of-LIME

Local Interpretable Model-agnostic Explanations (LIME) is a local explanation approach which produces a coarse heatmap highlighting the most important regions (i.e., superpixels) affecting the CNN's decision in image classification.

To visually explain decisions made by CNN models from different scales, we propose a multi-scale version of LIME to represent heatmaps of coarse to finer scales. Promising results for multi-scale classification heatmaps of natural images as well as histopathology images will be presented with both quantitative and qualitative validation.
